{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c995498",
   "metadata": {},
   "source": [
    "## Inicializadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2c49a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# pip install googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "201a4675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9068f4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000e8c3c7ddb</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave was an experimentto see how peo...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0020ae56ffbf</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They would rub it up with soda to make the sme...</td>\n",
       "      <td>-0.548304</td>\n",
       "      <td>0.506755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004e978e639e</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>In Egypt, there were many occupations and soci...</td>\n",
       "      <td>3.128928</td>\n",
       "      <td>4.231226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005ab0199905</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>The highest class was Pharaohs these people we...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0070c9e7af47</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The Third Wave developed  rapidly because the ...</td>\n",
       "      <td>3.272894</td>\n",
       "      <td>3.219757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id prompt_id                                               text  \\\n",
       "0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n",
       "1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n",
       "2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n",
       "3  005ab0199905    3b9047  The highest class was Pharaohs these people we...   \n",
       "4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n",
       "\n",
       "    content   wording  \n",
       "0  0.205683  0.380538  \n",
       "1 -0.548304  0.506755  \n",
       "2  3.128928  4.231226  \n",
       "3 -0.210614 -0.471415  \n",
       "4  3.272894  3.219757  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/summaries_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db142c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3b9047</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>814d6b</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prompt_id                                    prompt_question  \\\n",
       "0    39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "1    3b9047  In complete sentences, summarize the structure...   \n",
       "2    814d6b  Summarize how the Third Wave developed over su...   \n",
       "3    ebad26  Summarize the various ways the factory would u...   \n",
       "\n",
       "                prompt_title  \\\n",
       "0                 On Tragedy   \n",
       "1  Egyptian Social Structure   \n",
       "2             The Third Wave   \n",
       "3    Excerpt from The Jungle   \n",
       "\n",
       "                                         prompt_text  \n",
       "0  Chapter 13 \\r\\nAs the sequel to what has alrea...  \n",
       "1  Egyptian society was structured like a pyramid...  \n",
       "2  Background \\r\\nThe Third Wave experiment took ...  \n",
       "3  With one member trimming beef in a cannery, an...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions = pd.read_csv('../data/prompts_train.csv')\n",
    "df_questions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0b9402",
   "metadata": {},
   "source": [
    "### Traduzindo Os dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6d03fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from googletrans import Translator\n",
    "from translate import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81a544aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para traduzir um texto para outro idioma\n",
    "def translate_text(text, target_language):\n",
    "    translator = Translator(to_lang=target_language)\n",
    "    translation = translator.translate(text)\n",
    "    return translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee022cc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_questions_por = df_questions.copy()\n",
    "target_language = 'pt'\n",
    "df_questions_por['questao_proposta'] = df_questions['prompt_question'].apply(lambda x: translate_text(x, target_language))\n",
    "df_questions_por['questao_titulo'] = df_questions['prompt_title'].apply(lambda x: translate_text(x, target_language))\n",
    "# df_questions_por['questao_texto'] = df_questions['prompt_text'].apply(lambda x: translate_text(x, target_language))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d901b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions_por.to_csv('../data/df_questions_por.csv',index=False,sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75824366",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "target_language = 'pt'\n",
    "df_copy['texto'] = df['text'].apply(lambda x: translate_text(x, target_language))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd7de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa04e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.to_csv('../data/sumaries_pt.csv',index=False,sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b01222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instalando o transformers\n",
    "#pip install transformers\n",
    "#pip install --upgrade transformers torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab5ad44",
   "metadata": {},
   "source": [
    "### Carregando os modelos e tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c23e2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e87dedbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#somente bert\n",
    "bert_model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f973118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#somente gpt\n",
    "gpt_model = AutoModel.from_pretrained(\"gpt2\")\n",
    "gpt_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "798d23fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Exemplo de texto para teste.\"\n",
    "\n",
    "# Tokenizar o texto com o tokenizador do BERT\n",
    "bert_inputs = bert_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Executar o modelo BERT nos inputs\n",
    "bert_outputs = bert_model(**bert_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ae9851",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbd9e44",
   "metadata": {},
   "source": [
    "## criando um modelo bert para avaliação gramatical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfba998c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['prompt_id', 'prompt_question', 'prompt_title', 'prompt_text'], dtype='object')\n",
      "Index(['student_id', 'prompt_id', 'text', 'content', 'wording'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_questions.columns)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f64b847a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>student_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>00791789cc1f</td>\n",
       "      <td>1 element of an ideal tragedy is that it shoul...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>0086ef22de8f</td>\n",
       "      <td>The three elements of an ideal tragedy are:  H...</td>\n",
       "      <td>-0.970237</td>\n",
       "      <td>-0.417058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>0094589c7a22</td>\n",
       "      <td>Aristotle states that an ideal tragedy should ...</td>\n",
       "      <td>-0.387791</td>\n",
       "      <td>-0.584181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>00cd5736026a</td>\n",
       "      <td>One element of an Ideal tragedy is having a co...</td>\n",
       "      <td>0.088882</td>\n",
       "      <td>-0.594710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>00d98b8ff756</td>\n",
       "      <td>The 3 ideal of tragedy is how complex you need...</td>\n",
       "      <td>-0.687288</td>\n",
       "      <td>-0.460886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prompt_id                                    prompt_question prompt_title  \\\n",
       "0    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "1    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "2    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "3    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "4    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "\n",
       "                                         prompt_text    student_id  \\\n",
       "0  Chapter 13 \\r\\nAs the sequel to what has alrea...  00791789cc1f   \n",
       "1  Chapter 13 \\r\\nAs the sequel to what has alrea...  0086ef22de8f   \n",
       "2  Chapter 13 \\r\\nAs the sequel to what has alrea...  0094589c7a22   \n",
       "3  Chapter 13 \\r\\nAs the sequel to what has alrea...  00cd5736026a   \n",
       "4  Chapter 13 \\r\\nAs the sequel to what has alrea...  00d98b8ff756   \n",
       "\n",
       "                                                text   content   wording  \n",
       "0  1 element of an ideal tragedy is that it shoul... -0.210614 -0.471415  \n",
       "1  The three elements of an ideal tragedy are:  H... -0.970237 -0.417058  \n",
       "2  Aristotle states that an ideal tragedy should ... -0.387791 -0.584181  \n",
       "3  One element of an Ideal tragedy is having a co...  0.088882 -0.594710  \n",
       "4  The 3 ideal of tragedy is how complex you need... -0.687288 -0.460886  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#juntando os DF\n",
    "merged_df = df_questions.merge(df, on='prompt_id')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab0618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, AdamW\n",
    "import pandas as pd\n",
    "\n",
    "# Extraindo os dados relevantes do DataFrame merged_df\n",
    "text_data = merged_df['text'].tolist()  # Textos das redações\n",
    "content_data = merged_df['content'].tolist()  # Notas (conteúdo) das redações\n",
    "wording_data = merged_df['wording'].tolist()  # Notas (linguagem) das redações\n",
    "prompt_question_data = merged_df['prompt_question'].tolist()  # Perguntas associadas\n",
    "prompt_text_data = merged_df['prompt_text'].tolist()  # Textos de prompt associados\n",
    "\n",
    "# Carregar modelo BERT e tokenizador para o inglês\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)  # 2 rótulos: content e wording\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Preparar as entradas para o modelo\n",
    "input_texts = [f\"{text} {prompt_question} {prompt_text}\" for text, prompt_question, prompt_text in zip(text_data, prompt_question_data, prompt_text_data)]\n",
    "\n",
    "# Tokenizar e codificar os textos\n",
    "encoded_texts = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt', max_length=128)\n",
    "\n",
    "# Converter notas de content e wording para tensores do PyTorch\n",
    "notas_content = torch.tensor(content_data, dtype=torch.float32)\n",
    "notas_wording = torch.tensor(wording_data, dtype=torch.float32)\n",
    "\n",
    "# Concatenar as notas para criar um tensor de rótulos (target)\n",
    "rotulos = torch.stack((notas_content, notas_wording), dim=1)\n",
    "\n",
    "# Definir otimizador e treinamento\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Treinamento\n",
    "model.train()\n",
    "for epoch in range(5):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(**encoded_texts, labels=rotulos)\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Época {epoch+1}, Perda: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e4b8c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 3, Perda: -3.9181365966796875\n",
      "Época 4, Perda: -4.733118534088135\n",
      "Época 5, Perda: -5.846802711486816\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, AdamW\n",
    "\n",
    "\n",
    "# Extraindo os dados relevantes\n",
    "text_data = merged_df['text'].tolist()  # Textos das redações\n",
    "content_data = merged_df['content'].tolist()  # Notas (conteúdo) das redações\n",
    "wording_data = merged_df['wording'].tolist()  # Notas (linguagem) das redações\n",
    "prompt_question_data = merged_df['prompt_question'].tolist()  # Perguntas associadas\n",
    "prompt_text_data = merged_df['prompt_text'].tolist()  # Textos de prompt associados\n",
    "\n",
    "# Carregar modelo BERT e tokenizador para o inglês\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)  # 2 rótulos: content e wording\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Preparar as entradas para o modelo\n",
    "input_texts = [f\"{text} {prompt_question} {prompt_text}\" for text, prompt_question, prompt_text in zip(text_data, prompt_question_data, prompt_text_data)]\n",
    "\n",
    "# Tokenizar e codificar os textos\n",
    "encoded_texts = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt', max_length=128)\n",
    "\n",
    "# Converter notas de content e wording para tensores do PyTorch\n",
    "notas_content = torch.tensor(content_data, dtype=torch.float32)\n",
    "notas_wording = torch.tensor(wording_data, dtype=torch.float32)\n",
    "\n",
    "# Concatenar as notas para criar um tensor de rótulos (target)\n",
    "rotulos = torch.stack((notas_content, notas_wording), dim=1)\n",
    "\n",
    "# Definir otimizador e treinamento\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "batch_size = 8  # Tamanho do lote\n",
    "gradient_accumulation_steps = 2  # Acumulação de gradientes a cada 2 mini-lotes\n",
    "\n",
    "model.train()\n",
    "for epoch in range(5):\n",
    "    optimizer.zero_grad()\n",
    "    for batch_start in range(0, len(encoded_texts['input_ids']), batch_size):\n",
    "        batch_end = batch_start + batch_size\n",
    "        batch_inputs = {k: v[batch_start:batch_end] for k, v in encoded_texts.items()}\n",
    "        batch_labels = rotulos[batch_start:batch_end]\n",
    "        outputs = model(**batch_inputs, labels=batch_labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        if (batch_start // batch_size) % gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "    print(f\"Época {epoch+1}, Perda: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de18876a",
   "metadata": {},
   "source": [
    "## Salvando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d7c1fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data\\\\tokenizer_config.json',\n",
       " '../data\\\\special_tokens_map.json',\n",
       " '../data\\\\vocab.txt',\n",
       " '../data\\\\added_tokens.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caminho_salvar = \"../data\"\n",
    "\n",
    "# Salvando o modelo\n",
    "model.save_pretrained(caminho_salvar)\n",
    "tokenizer.save_pretrained(caminho_salvar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d09ffb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 element of an ideal tragedy is that it should be arranged on a complex plan.  Another element of an ideal tragedy is that it should only have one main issue. The last element of an ideal tragedy is that it should have a double thread plot and an opposite catastrophe for both good and bad.\n"
     ]
    }
   ],
   "source": [
    "text_sample = merged_df[:1]['text'].values[0]\n",
    "print(text_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7fbf39f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nota de Conteúdo: 25.637664794921875\n",
      "Nota de Linguagem: 23.27189064025879\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Caminho onde o modelo foi salvo\n",
    "caminho_modelo = caminho_salvar\n",
    "\n",
    "# Carregar modelo e tokenizador\n",
    "model = BertForSequenceClassification.from_pretrained(caminho_modelo)\n",
    "tokenizer = BertTokenizer.from_pretrained(caminho_modelo)\n",
    "\n",
    "# Texto para avaliar\n",
    "texto_a_avaliar = text_sample\n",
    "\n",
    "# Tokenizar e codificar o texto\n",
    "input_text = tokenizer(texto_a_avaliar, padding=True, truncation=True, return_tensors='pt', max_length=128)\n",
    "\n",
    "# Fazer a previsão\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**input_text)\n",
    "    notas_content, notas_wording = outputs.logits[0]\n",
    "\n",
    "print(f\"Nota de Conteúdo: {notas_content.item()}\")\n",
    "print(f\"Nota de Linguagem: {notas_wording.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "149f12e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    content   wording\n",
       "0 -0.210614 -0.471415"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[:1][['content','wording']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
